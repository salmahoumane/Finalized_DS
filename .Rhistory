Variable == "work_time_weekly" ~ "Work Time Weekly",
Variable == "net_income" ~ "Net Income",
Variable == "total_years_unemployment" ~ "Total Years Unemployed",
Variable == "worr_financial_dummy" ~ "Financial Worries (Dummy)",
Variable == "smoking_dummy" ~ "Smoking (Dummy)",
Variable == "worr_health_dummy" ~ "Worries About Health (Dummy)",
Variable == "worr_economic_dummy" ~ "Worries About the Economy (Dummy)",
Variable == "BMI" ~ "BMI",
Variable == "age" ~ "Age",
Variable == "university_dummy" ~ "University (Dummy)",
Variable == "married_dummy" ~ "Married (Dummy)",
Variable == "white_collar_dummy" ~ "White Collar Job (Dummy)",
Variable == "self_employed_dummy" ~ "Self Employed (Dummy)",
TRUE ~ Variable
)
)
# Plotting non-zero coefficients with cleaner labels
ggplot(non_zero_coefficients, aes(x = reorder(Variable, Coefficient), y = Coefficient, fill = Coefficient > 0)) +
geom_bar(stat = "identity", color = "black") +
coord_flip() +  # Flip coordinates for better readability
labs(
title = "Non-Zero Coefficients from Lasso Classification Balanced",
x = "",
y = "Coefficient Value"
) +
scale_fill_manual(
values = c("#FF0000", "#1E2B4F"),  # Red for negative, dark blue for positive
guide = "none"  # Remove the legend
) +
theme_minimal(base_size = 14) +
theme(
# Backgrounds
panel.background = element_rect(fill = "white", color = NA),  # White background
plot.background = element_rect(fill = "white", color = NA),  # White outer background
# Gridlines
panel.grid.major = element_blank(),  # Remove major grid lines
panel.grid.minor = element_blank(),  # Remove minor grid lines
# Axis styling
axis.title.x = element_blank(),  # Remove x-axis title
axis.title.y = element_blank(),  # Remove y-axis title
axis.text.x = element_text(size = 12, color = "#1E2B4F"),  # Dark blue x-axis text
axis.text.y = element_text(size = 12, face = "bold", color = "#1E2B4F"),  # Bold and dark blue y-axis text
# Title styling
plot.title = element_text(face = "bold", size = 16, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),  # Centered and bold title
# Adjust overall plot margins
plot.margin = ggplot2::margin(t = 20, r = 100, b = 20, l = 20)  # Add more space around the plot
)
#Save Graph
ggsave("lasso_coefficients_classification_balanced.png", plot = last_plot(), width = 16, height = 8, dpi = 300)
# Convert data to panel format
panel_data <- pdata.frame(main, index = c("pid", "syear"))  # pid = individual ID, syear = time
# Prepare data for LASSO regression
lasso_data <- panel_data %>%
dplyr::select(
pid, syear, health_decline_2yrs, health_in_2yrs, worr_health_dummy, health, BMI, smoking_dummy, life_satisfaction, health_satisfaction,
tenure, net_income, work_time_weekly, total_years_unemployment,
worr_job_dummy, worr_financial_dummy, worr_economic_dummy,
male, age, university_dummy, married_dummy, white_collar_dummy, self_employed_dummy
) %>%
na.omit()  # Remove missing values
# Split the data into training and test data
set.seed(12345) # For reproducibility
trainIndex <- createDataPartition(lasso_data$health_decline_2yrs, p = 0.7, list = FALSE)
# Convert trainIndex to a vector
trainIndex <- as.vector(trainIndex)
# Use the vector to split the data
trainData <- lasso_data[trainIndex, ]
testData <- lasso_data[-trainIndex, ]
# Exclude pid and syear and the outcome variable to avoid overfitting and exclude health here too
trainData <- trainData %>% select(-pid, -syear, -health_in_2yrs)
testData <- testData %>% select(-pid, -syear, health_in_2yrs)
# Define the number of instances to keep (equal to minority class count)
N_target <- sum(trainData$health_decline_2yrs == 1) * 2  # 1:1 ratio
# Perform random undersampling
balanced_data <- ovun.sample(
health_decline_2yrs ~ .,  # Target variable
data = trainData,
method = "under",  # Perform undersampling
N = N_target,  # Keep equal numbers in both classes
seed = 123
)$data  # Extract the balanced dataset
# Check new class distribution
table(balanced_data$health_decline_2yrs)
## We now have a balanced dataset with 13035 occurences of each group.
# Standardize numerical variables **AFTER RESAMPLING**
numerical_vars <- c(
"BMI", "smoking_dummy", "life_satisfaction", "health_satisfaction",
"tenure", "net_income", "work_time_weekly", "total_years_unemployment",
"worr_job_dummy", "worr_financial_dummy", "worr_economic_dummy",
"male", "age",  "worr_health_dummy", "health",
"married_dummy", "university_dummy", "self_employed_dummy", "white_collar_dummy"
)
# Apply pre-processing (center and scale) only to the selected numerical columns
preProcValues <- preProcess(balanced_data[, numerical_vars], method = c("center", "scale"))
# Standardize the training data
balanced_data[, numerical_vars] <- predict(preProcValues, balanced_data[, numerical_vars])
# Standardize the test data
testData[, numerical_vars] <- predict(preProcValues, testData[, numerical_vars])
# Convert `health_decline_2yrs` to factor
balanced_data$health_decline_2yrs <- factor(balanced_data$health_decline_2yrs, levels = c(0, 1), labels = c("No", "Yes"))
testData$health_decline_2yrs <- factor(testData$health_decline_2yrs, levels = c(0, 1), labels = c("No", "Yes"))
# Set up the training control
train_control <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
# Train the LASSO model for classification using the balanced dataset
set.seed(12345)
lasso_model_balanced <- train(
health_decline_2yrs ~ .,
data = balanced_data,
method = "glmnet",        # Specify LASSO
family = "binomial",      # Classification for binary outcome
trControl = train_control,  # Use predefined training control
tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 0.5, by = 0.001)), # LASSO tuning grid
metric = "ROC"  # Use ROC as the evaluation metric
)
# Display the best lambda value and model summary
print(lasso_model_balanced$bestTune)
# Extract the cross-validation results
cv_results <- lasso_model_balanced$results
# Create a ggplot visualization for Cross-validation
ggplot(cv_results, aes(x = log(lambda), y = ROC, color = ROC)) +
geom_point(size = 2, alpha = 0.8) +  # Add points for each lambda value
geom_line(size = 1) +  # Add a line to connect points
labs(
title = "LASSO Balanced Model Cross-Validation Results",
subtitle = "ROC vs. Log(Lambda) Across Cross-Validation Folds",
x = "Log(Lambda)",
y = "ROC"
) +
scale_color_gradient(low = "#A6CEE3", high = "#1E2B4F") +  # Gradient from light blue to dark blue
theme_minimal(base_size = 14) +
theme(
panel.background = element_rect(fill = "white", color = NA),
plot.background = element_rect(fill = "white", color = NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text.x = element_text(size = 12, color = "#1E2B4F"),
axis.text.y = element_text(size = 12, color = "#1E2B4F"),
axis.title.x = element_text(size = 14, face = "bold", color = "#1E2B4F"),
axis.title.y = element_text(size = 14, face = "bold", color = "#1E2B4F"),
plot.title = element_text(face = "bold", size = 16, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),
plot.subtitle = element_text(size = 14, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),
plot.margin = ggplot2::margin(t = 20, r = 100, b = 20, l = 20),
legend.position = "none"
)
# Save Graph
ggsave("lasso_model_classification_balanced.png", plot = last_plot(), width = 16, height = 8, dpi = 300)
# Model Evaluation on Original Test Set
lasso_predictions_balanced <- predict(lasso_model_balanced, newdata = testData, type = "prob")
# Predict binary outcomes (threshold = 0.5)
predicted_classes <- ifelse(lasso_predictions_balanced[, "Yes"] > 0.5, "Yes", "No")
# Confusion matrix
conf_matrix <- confusionMatrix(factor(predicted_classes, levels = c("No", "Yes")),
factor(testData$health_decline_2yrs, levels = c("No", "Yes")))
print(conf_matrix)
# Evaluate model performance
print(paste0("Accuracy: ", conf_matrix$overall["Accuracy"]))
print(paste0("Sensitivity: ", conf_matrix$byClass["Sensitivity"]))
print(paste0("Specificity: ", conf_matrix$byClass["Specificity"]))
# Convert sparse matrix to data frame and filter non-zero coefficients
coefficients <- coef(lasso_model_balanced$finalModel, s = lasso_model_balanced$bestTune$lambda)
non_zero_coefficients <- data.frame(
Variable = rownames(as.matrix(coefficients)),
Coefficient = as.numeric(as.matrix(coefficients))
) %>%
filter(Coefficient != 0)  # Keep only non-zero coefficients
# Remove the intercept and rename variables
non_zero_coefficients <- non_zero_coefficients %>%
filter(Variable != "(Intercept)") %>%  # Remove the intercept
mutate(
Variable = case_when(  # Rename variables for cleaner labels
Variable == "health" ~ "Health",
Variable == "health_satisfaction" ~ "Health Satisfaction",
Variable == "life_satisfaction" ~ "Life Satisfaction",
Variable == "educ" ~ "Education Level",
Variable == "male" ~ "Gender (Male=1)",
Variable == "worr_job_dummy" ~ "Job Worries (Dummy)",
Variable == "tenure" ~ "Tenure",
Variable == "work_time_weekly" ~ "Work Time Weekly",
Variable == "net_income" ~ "Net Income",
Variable == "total_years_unemployment" ~ "Total Years Unemployed",
Variable == "worr_financial_dummy" ~ "Financial Worries (Dummy)",
Variable == "smoking_dummy" ~ "Smoking (Dummy)",
Variable == "worr_health_dummy" ~ "Worries About Health (Dummy)",
Variable == "worr_economic_dummy" ~ "Worries About the Economy (Dummy)",
Variable == "BMI" ~ "BMI",
Variable == "age" ~ "Age",
Variable == "university_dummy" ~ "University (Dummy)",
Variable == "married_dummy" ~ "Married (Dummy)",
Variable == "white_collar_dummy" ~ "White Collar Job (Dummy)",
Variable == "self_employed_dummy" ~ "Self Employed (Dummy)",
TRUE ~ Variable
)
)
# Plotting non-zero coefficients with cleaner labels
ggplot(non_zero_coefficients, aes(x = reorder(Variable, Coefficient), y = Coefficient, fill = Coefficient > 0)) +
geom_bar(stat = "identity", color = "black") +
coord_flip() +  # Flip coordinates for better readability
labs(
title = "Non-Zero Coefficients from Lasso Classification Balanced",
x = "",
y = "Coefficient Value"
) +
scale_fill_manual(
values = c("#FF0000", "#1E2B4F"),  # Red for negative, dark blue for positive
guide = "none"  # Remove the legend
) +
theme_minimal(base_size = 14) +
theme(
# Backgrounds
panel.background = element_rect(fill = "white", color = NA),  # White background
plot.background = element_rect(fill = "white", color = NA),  # White outer background
# Gridlines
panel.grid.major = element_blank(),  # Remove major grid lines
panel.grid.minor = element_blank(),  # Remove minor grid lines
# Axis styling
axis.title.x = element_blank(),  # Remove x-axis title
axis.title.y = element_blank(),  # Remove y-axis title
axis.text.x = element_text(size = 12, color = "#1E2B4F"),  # Dark blue x-axis text
axis.text.y = element_text(size = 12, face = "bold", color = "#1E2B4F"),  # Bold and dark blue y-axis text
# Title styling
plot.title = element_text(face = "bold", size = 16, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),  # Centered and bold title
# Adjust overall plot margins
plot.margin = ggplot2::margin(t = 20, r = 100, b = 20, l = 20)  # Add more space around the plot
)
#Save Graph
ggsave("lasso_coefficients_classification_balanced.png", plot = last_plot(), width = 16, height = 8, dpi = 300)
# Convert data to panel format
panel_data <- pdata.frame(main, index = c("pid", "syear"))  # pid = individual ID, syear = time
# Prepare data for LASSO regression
lasso_data <- panel_data %>%
dplyr::select(
pid, syear, health_decline_2yrs, health_in_2yrs, worr_health_dummy, health, BMI, smoking_dummy, life_satisfaction, health_satisfaction,
tenure, net_income, work_time_weekly, total_years_unemployment,
worr_job_dummy, worr_financial_dummy, worr_economic_dummy,
male, age, university_dummy, married_dummy, white_collar_dummy, self_employed_dummy
) %>%
na.omit()  # Remove missing values
# Split the data into training and test data
set.seed(12345) # For reproducibility
trainIndex <- createDataPartition(lasso_data$health_decline_2yrs, p = 0.7, list = FALSE)
# Convert trainIndex to a vector
trainIndex <- as.vector(trainIndex)
# Use the vector to split the data
trainData <- lasso_data[trainIndex, ]
testData <- lasso_data[-trainIndex, ]
# Exclude pid and syear and the outcome variable to avoid overfitting and exclude health here too
trainData <- trainData %>% select(-pid, -syear, -health_in_2yrs, -health)
testData <- testData %>% select(-pid, -syear, -health_in_2yrs, -health)
# Define the number of instances to keep (equal to minority class count)
N_target <- sum(trainData$health_decline_2yrs == 1) * 2  # 1:1 ratio
# Perform random undersampling
balanced_data <- ovun.sample(
health_decline_2yrs ~ .,  # Target variable
data = trainData,
method = "under",  # Perform undersampling
N = N_target,  # Keep equal numbers in both classes
seed = 123
)$data  # Extract the balanced dataset
# Check new class distribution
table(balanced_data$health_decline_2yrs)
## We now have a balanced dataset with 13035 occurences of each group.
# Standardize numerical variables **AFTER RESAMPLING**
numerical_vars <- c(
"BMI", "smoking_dummy", "life_satisfaction", "health_satisfaction",
"tenure", "net_income", "work_time_weekly", "total_years_unemployment",
"worr_job_dummy", "worr_financial_dummy", "worr_economic_dummy",
"male", "age",  "worr_health_dummy",
"married_dummy", "university_dummy", "self_employed_dummy", "white_collar_dummy"
)
# Apply pre-processing (center and scale) only to the selected numerical columns
preProcValues <- preProcess(balanced_data[, numerical_vars], method = c("center", "scale"))
# Standardize the training data
balanced_data[, numerical_vars] <- predict(preProcValues, balanced_data[, numerical_vars])
# Standardize the test data
testData[, numerical_vars] <- predict(preProcValues, testData[, numerical_vars])
# Convert `health_decline_2yrs` to factor
balanced_data$health_decline_2yrs <- factor(balanced_data$health_decline_2yrs, levels = c(0, 1), labels = c("No", "Yes"))
testData$health_decline_2yrs <- factor(testData$health_decline_2yrs, levels = c(0, 1), labels = c("No", "Yes"))
# Set up the training control
train_control <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
# Train the LASSO model for classification using the balanced dataset
set.seed(12345)
lasso_model_balanced <- train(
health_decline_2yrs ~ .,
data = balanced_data,
method = "glmnet",        # Specify LASSO
family = "binomial",      # Classification for binary outcome
trControl = train_control,  # Use predefined training control
tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 0.5, by = 0.001)), # LASSO tuning grid
metric = "ROC"  # Use ROC as the evaluation metric
)
# Display the best lambda value and model summary
print(lasso_model_balanced$bestTune)
# Extract the cross-validation results
cv_results <- lasso_model_balanced$results
# Create a ggplot visualization for Cross-validation
ggplot(cv_results, aes(x = log(lambda), y = ROC, color = ROC)) +
geom_point(size = 2, alpha = 0.8) +  # Add points for each lambda value
geom_line(size = 1) +  # Add a line to connect points
labs(
title = "LASSO Balanced Model Cross-Validation Results",
subtitle = "ROC vs. Log(Lambda) Across Cross-Validation Folds",
x = "Log(Lambda)",
y = "ROC"
) +
scale_color_gradient(low = "#A6CEE3", high = "#1E2B4F") +  # Gradient from light blue to dark blue
theme_minimal(base_size = 14) +
theme(
panel.background = element_rect(fill = "white", color = NA),
plot.background = element_rect(fill = "white", color = NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text.x = element_text(size = 12, color = "#1E2B4F"),
axis.text.y = element_text(size = 12, color = "#1E2B4F"),
axis.title.x = element_text(size = 14, face = "bold", color = "#1E2B4F"),
axis.title.y = element_text(size = 14, face = "bold", color = "#1E2B4F"),
plot.title = element_text(face = "bold", size = 16, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),
plot.subtitle = element_text(size = 14, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),
plot.margin = ggplot2::margin(t = 20, r = 100, b = 20, l = 20),
legend.position = "none"
)
# Save Graph
ggsave("lasso_model_classification_balanced.png", plot = last_plot(), width = 16, height = 8, dpi = 300)
# Model Evaluation on Original Test Set
lasso_predictions_balanced <- predict(lasso_model_balanced, newdata = testData, type = "prob")
# Predict binary outcomes (threshold = 0.5)
predicted_classes <- ifelse(lasso_predictions_balanced[, "Yes"] > 0.5, "Yes", "No")
# Confusion matrix
conf_matrix <- confusionMatrix(factor(predicted_classes, levels = c("No", "Yes")),
factor(testData$health_decline_2yrs, levels = c("No", "Yes")))
print(conf_matrix)
# Evaluate model performance
print(paste0("Accuracy: ", conf_matrix$overall["Accuracy"]))
print(paste0("Sensitivity: ", conf_matrix$byClass["Sensitivity"]))
print(paste0("Specificity: ", conf_matrix$byClass["Specificity"]))
# Convert sparse matrix to data frame and filter non-zero coefficients
coefficients <- coef(lasso_model_balanced$finalModel, s = lasso_model_balanced$bestTune$lambda)
non_zero_coefficients <- data.frame(
Variable = rownames(as.matrix(coefficients)),
Coefficient = as.numeric(as.matrix(coefficients))
) %>%
filter(Coefficient != 0)  # Keep only non-zero coefficients
# Remove the intercept and rename variables
non_zero_coefficients <- non_zero_coefficients %>%
filter(Variable != "(Intercept)") %>%  # Remove the intercept
mutate(
Variable = case_when(  # Rename variables for cleaner labels
Variable == "health" ~ "Health",
Variable == "health_satisfaction" ~ "Health Satisfaction",
Variable == "life_satisfaction" ~ "Life Satisfaction",
Variable == "educ" ~ "Education Level",
Variable == "male" ~ "Gender (Male=1)",
Variable == "worr_job_dummy" ~ "Job Worries (Dummy)",
Variable == "tenure" ~ "Tenure",
Variable == "work_time_weekly" ~ "Work Time Weekly",
Variable == "net_income" ~ "Net Income",
Variable == "total_years_unemployment" ~ "Total Years Unemployed",
Variable == "worr_financial_dummy" ~ "Financial Worries (Dummy)",
Variable == "smoking_dummy" ~ "Smoking (Dummy)",
Variable == "worr_health_dummy" ~ "Worries About Health (Dummy)",
Variable == "worr_economic_dummy" ~ "Worries About the Economy (Dummy)",
Variable == "BMI" ~ "BMI",
Variable == "age" ~ "Age",
Variable == "university_dummy" ~ "University (Dummy)",
Variable == "married_dummy" ~ "Married (Dummy)",
Variable == "white_collar_dummy" ~ "White Collar Job (Dummy)",
Variable == "self_employed_dummy" ~ "Self Employed (Dummy)",
TRUE ~ Variable
)
)
# Plotting non-zero coefficients with cleaner labels
ggplot(non_zero_coefficients, aes(x = reorder(Variable, Coefficient), y = Coefficient, fill = Coefficient > 0)) +
geom_bar(stat = "identity", color = "black") +
coord_flip() +  # Flip coordinates for better readability
labs(
title = "Non-Zero Coefficients from Lasso Balanced",
x = "",
y = "Coefficient Value"
) +
scale_fill_manual(
values = c("#FF0000", "#1E2B4F"),  # Red for negative, dark blue for positive
guide = "none"  # Remove the legend
) +
theme_minimal(base_size = 14) +
theme(
# Backgrounds
panel.background = element_rect(fill = "white", color = NA),  # White background
plot.background = element_rect(fill = "white", color = NA),  # White outer background
# Gridlines
panel.grid.major = element_blank(),  # Remove major grid lines
panel.grid.minor = element_blank(),  # Remove minor grid lines
# Axis styling
axis.title.x = element_blank(),  # Remove x-axis title
axis.title.y = element_blank(),  # Remove y-axis title
axis.text.x = element_text(size = 12, color = "#1E2B4F"),  # Dark blue x-axis text
axis.text.y = element_text(size = 12, face = "bold", color = "#1E2B4F"),  # Bold and dark blue y-axis text
# Title styling
plot.title = element_text(face = "bold", size = 16, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),  # Centered and bold title
# Adjust overall plot margins
plot.margin = ggplot2::margin(t = 20, r = 100, b = 20, l = 20)  # Add more space around the plot
)
#Save Graph
ggsave("lasso_coefficients_classification_balanced.png", plot = last_plot(), width = 16, height = 8, dpi = 300)
# Convert data to panel format
panel_data <- pdata.frame(main, index = c("pid", "syear"))  # pid = individual ID, syear = time
# Prepare data for LASSO regression
lasso_data <- panel_data %>%
dplyr::select(
pid, syear, health_decline_2yrs, health_in_2yrs, worr_health_dummy, health, BMI, smoking_dummy, life_satisfaction, health_satisfaction,
tenure, net_income, work_time_weekly, total_years_unemployment,
worr_job_dummy, worr_financial_dummy, worr_economic_dummy,
male, age, university_dummy, married_dummy, white_collar_dummy, self_employed_dummy
) %>%
na.omit()  # Remove missing values
# Split the data into training and test data
set.seed(12345) # For reproducibility
trainIndex <- createDataPartition(lasso_data$health_decline_2yrs, p = 0.7, list = FALSE)
# Convert trainIndex to a vector
trainIndex <- as.vector(trainIndex)
# Use the vector to split the data
trainData <- lasso_data[trainIndex, ]
testData <- lasso_data[-trainIndex, ]
# Exclude pid and syear and the outcome variable to avoid overfitting and exclude health here too
trainData <- trainData %>% select(-pid, -syear, -health_in_2yrs, -health)
testData <- testData %>% select(-pid, -syear, -health_in_2yrs, -health)
# Define the number of instances to keep (equal to minority class count)
N_target <- sum(trainData$health_decline_2yrs == 1) * 2  # 1:1 ratio
# Perform random undersampling
balanced_data <- ovun.sample(
health_decline_2yrs ~ .,  # Target variable
data = trainData,
method = "under",  # Perform undersampling
N = N_target,  # Keep equal numbers in both classes
seed = 123
)$data  # Extract the balanced dataset
# Check new class distribution
table(balanced_data$health_decline_2yrs)
## We now have a balanced dataset with 13035 occurences of each group.
# Standardize numerical variables **AFTER RESAMPLING**
numerical_vars <- c(
"BMI", "smoking_dummy", "life_satisfaction", "health_satisfaction",
"tenure", "net_income", "work_time_weekly", "total_years_unemployment",
"worr_job_dummy", "worr_financial_dummy", "worr_economic_dummy",
"male", "age",  "worr_health_dummy",
"married_dummy", "university_dummy", "self_employed_dummy", "white_collar_dummy"
)
# Apply pre-processing (center and scale) only to the selected numerical columns
preProcValues <- preProcess(balanced_data[, numerical_vars], method = c("center", "scale"))
# Standardize the training data
balanced_data[, numerical_vars] <- predict(preProcValues, balanced_data[, numerical_vars])
# Standardize the test data
testData[, numerical_vars] <- predict(preProcValues, testData[, numerical_vars])
# Convert `health_decline_2yrs` to factor
balanced_data$health_decline_2yrs <- factor(balanced_data$health_decline_2yrs, levels = c(0, 1), labels = c("No", "Yes"))
testData$health_decline_2yrs <- factor(testData$health_decline_2yrs, levels = c(0, 1), labels = c("No", "Yes"))
# Set up the training control
train_control <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
# Train the LASSO model for classification using the balanced dataset
set.seed(12345)
lasso_model_balanced <- train(
health_decline_2yrs ~ .,
data = balanced_data,
method = "glmnet",        # Specify LASSO
family = "binomial",      # Classification for binary outcome
trControl = train_control,  # Use predefined training control
tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 0.5, by = 0.001)), # LASSO tuning grid
metric = "ROC"  # Use ROC as the evaluation metric
)
# Display the best lambda value and model summary
print(lasso_model_balanced$bestTune)
# Extract the cross-validation results
cv_results <- lasso_model_balanced$results
# Create a ggplot visualization for Cross-validation
ggplot(cv_results, aes(x = log(lambda), y = ROC, color = ROC)) +
geom_point(size = 2, alpha = 0.8) +  # Add points for each lambda value
geom_line(size = 1) +  # Add a line to connect points
labs(
title = "LASSO Balanced Model Cross-Validation Results",
subtitle = "ROC vs. Log(Lambda) Across Cross-Validation Folds",
x = "Log(Lambda)",
y = "ROC"
) +
scale_color_gradient(low = "#A6CEE3", high = "#1E2B4F") +  # Gradient from light blue to dark blue
theme_minimal(base_size = 14) +
theme(
panel.background = element_rect(fill = "white", color = NA),
plot.background = element_rect(fill = "white", color = NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text.x = element_text(size = 12, color = "#1E2B4F"),
axis.text.y = element_text(size = 12, color = "#1E2B4F"),
axis.title.x = element_text(size = 14, face = "bold", color = "#1E2B4F"),
axis.title.y = element_text(size = 14, face = "bold", color = "#1E2B4F"),
plot.title = element_text(face = "bold", size = 16, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),
plot.subtitle = element_text(size = 14, hjust = 0.5, color = "#1E2B4F", margin = ggplot2::margin(b = 10)),
plot.margin = ggplot2::margin(t = 20, r = 100, b = 20, l = 20),
legend.position = "none"
)
# Save Graph
ggsave("lasso_model_classification_balanced_no_health.png", plot = last_plot(), width = 16, height = 8, dpi = 300)
# Model Evaluation on Original Test Set
lasso_predictions_balanced <- predict(lasso_model_balanced, newdata = testData, type = "prob")
# Predict binary outcomes (threshold = 0.5)
predicted_classes <- ifelse(lasso_predictions_balanced[, "Yes"] > 0.5, "Yes", "No")
# Confusion matrix
conf_matrix <- confusionMatrix(factor(predicted_classes, levels = c("No", "Yes")),
factor(testData$health_decline_2yrs, levels = c("No", "Yes")))
print(conf_matrix)
# Evaluate model performance
print(paste0("Accuracy: ", conf_matrix$overall["Accuracy"]))
print(paste0("Sensitivity: ", conf_matrix$byClass["Sensitivity"]))
print(paste0("Specificity: ", conf_matrix$byClass["Specificity"]))
